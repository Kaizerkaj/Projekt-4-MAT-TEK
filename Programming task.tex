\section{Programmerings opgaver}



\subsection{Programmering opgaver 1.}

Formålet med denne opgave var at lave et script indeholdende funktioner som kunne beregne PageRank beskrevet ved metoden for \emph{Random Surfer Model}. Vi lavede en funktion \texttt{random\_step}. Det denne funktion gjorde meget kort fortalt var at give sandsynligheden for at udvælge de enkelte sider. I denne funktion skulle man angive hvilken hjemmeside man starter fra. Her er et eksempel med $d = 0.85$ og hvor vi starter på hjemmesiden $A1.html$:
\begin{figure}[!h]
    \centering
    \includegraphics[width = \linewidth]{Billeder/surf_step_test.png}
    \caption{Eksempel af funktionen \texttt{random\_step}.}
    \label{fig:my_label}
\end{figure}

Funktionen har inputtet: \texttt{random\_step(web,page,d)}, hvor web er sættet $W$. Denne funktion bruges så til funktionen \texttt{random\_surf} som kan bestemme hjemmesidernes PageRank. Denne funktion tager inputtet: \texttt{random\_surf(web,d,n)}. $web$ og $d$ er det samme som før, hvor $n$ er hvor mange gange funktionen skal køre (jf. betydningen af $n$ i afsnittet \emph{Random Surfer Model}). Her er et eksempel på funktionen med samme sæt $W$ som før:
\begin{figure}[!h]
    \centering
    \includegraphics[width = \linewidth]{Billeder/random_surf_test.png}
    \caption{Eksempel af funktionen \texttt{random\_surf}.}
    \label{fig:my_label}
\end{figure}

For at se nærmere på koden bedes du henvises til bilag.

\subsection{Programmering opgaver 2.}

FORSTÅR IK RECURSIVE TBH

\subsection{Programmering opgaver 3.}


\subsection*{Programmering opgaver 4.}
Programmeringsopgave 4 havde til formål at modificere vores funktioner således at den kan håndtere "sinks". Når en hjemmeside kaldes for en sink skal det forstås 

\subsection*{Tidsovervejelser}
\subsubsection*{Hvordan beregnes tiden af en funktion i Python}
For at få konkrete værdier for hvor lang tid det tager metoderne at beregne PageRank værdierne, så brugte vi \emph{time} modulet indbygget i Python. Her kan der bruges \texttt{time.time()} til at gemme en start-tid før funktionen er startet og en tid når den er stoppet. Den totale tid det tager beregnes så ved at trække start-tiden fra stop-tiden.

\subsubsection{Analyse af Tidsforbrug}
\begin{table}[!h]
    \centering
    \begin{tabular}{c|l|l|l|l}
        \# hjemmesider & Random Surfer & Recursive & Limit & Eigenvectors \\
        \hline
        $N = 10$       & 1.8134 s   & 0.0000 s   & 0.0000 s   & 0.0010 s   \\
        $N = 75$       & 3.4769 s   & 0.0110 s   & 0.0020 s   & 0.0028 s   \\
        $N = 250$      & 7.6943 s   & 0.0860 s   & 0.0090 s   & 0.0699 s
    \end{tabular}
    \caption{En tabel over metodernes tidsforbrug afhængigt at $n$, antallet af webpages i simulationen. Når der står "0.0000" så betyder det ikke faktisk 0, men skyldes numeriske fejl fra python fordi tallet er så lille. Her refererer "Random Surfer" til Random surfer modellen med en dæmpningsfaktor, "Recursive" er den rekursive model, "Limit" er hvor der anvendes at $A$ er en \textit{Markov matrix} med positive værdier og "Eigenvectors er hvor der findes den korrekte egenvektor og den skaleres tilpasseligt. Naturligvis er dæmpningsfaktoren $d$ ens for alle modellerne som er $d = 0.85$.}
    \label{tidsFigur}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width = \linewidth]{Billeder/Kode1.png}
    \caption{Del af kode fra \texttt{random\_surfer} funktionen}
\end{figure}


På Tabel~\ref{tidsFigur}, kan det ses at Random Surfer modellen er den klart mest langsomme model som der er. Dette giver også mening siden at der for hver iteration af algoritmen skal køres \texttt{surf\_step} funktionen, som beregner sandsynlighedsfordelingen. En hurtig måde der kunne skæres ned på tiden brugt i denne funktion, vil være ved at gemme resultatet af \texttt{surf\_step} og så genbruge det, så det ikke skal beregnes hver gang igen.

Det kan ses ved at kigge på alle resultaterne at Limit-metoden er klart den hurtigste. Denne I dette tilfælde har vi dog ganget matricen med sig selv 20 gange. Denne værdi kan forøges så meget som man vil, på bekostningen af det så vil tage længere tid, men resultatet vil blive mere præcist.

Den rekursive model kan også tilpasses så den tager mindre tid, ved at ændre på \texttt{stopvalue} eller \texttt{max\_iterations}.

Egenværdi metoden virker som den som generelt er bedst, da den finder den matematiske korrekte løsning og tager meget kort tid

\subsubsection{Hvad der kunne undersøges}
Det kunne være interessant at undersøge hvilket forhold der er mellem metodernes tid og $N$. Dette er vigtigt at vide, hvis man skal kunne have muligheden for at skalere algoritmen til en højere $N$, hvilket er tilfældet for \emph{Google}.

