
\section{Løsninger til teoretiske problemer:}


\subsection*{Problem 1.} \label{problem 1}

Ligningen (2.3) viser, at x er lig med en kombination af to ting: $\frac{(1-d)}{N}e$ og $d\cdot L\cdot x$. $e$ er en vektor bestående af kun 1'ere, $E_N$ er en matrix bestående af kun 1'ere.
Da $L$ er en kendt matrix, og $d$ er en kendt konstant og $N$ er en kendt heltal, kan vi erstatte e og $E_N$ i ligningen (2.3) for at få :
$$x = \frac{(1-d)}{N}E_N + d\cdot L\cdot x$$
Vi kan derefter definere $M_d$ som $\frac{(1-d)}{N} \cdot E_N + d \cdot L$ og erstatte det i ligningen (2.3) for at få:
$$x = M_d \cdot x$$
Så ligningen (2.3) kan skrives som ligningen (2.4) hvor $$M_d = \frac{(1-d)}{N}E_N + d \cdot L$$
Så vi har vist, at ligningen (2.3) kan skrives om som ligningen (2.4)



\subsection*{Problem 2.}

Bevis for at en Markov matrice med en potens $m$ ligeså er en Markov matrice:

Der er forskellige regler før at en Markov matrice $(A)$ er rigtigt. For det første kan $A$ ikke indeholde negative tal. Derudover skal summen af rækkerne give 1. En Markov matrice skal også være en $n \times n$ matrix. Dette vil sige, at hvis vi tager en Markov matrix $A$ og hæver den til en potens $m$ altså: $A^m$, vil den resulterende matrix også være en Markov matrix for enhver $m = 0,1,2,3,...$

Dette skyldes, at kan hæve en matrix til en potens $m$ simpelthen betyder at multiplicere matricen med sig selv $m$ gange. Derfor vil den resulterende matrix stadig have ikke-negative elementer og hver række vil stadig give summen 1, da disse egenskaber bevares under matrixmultiplikation.

\subsection*{Problem 3.}

Sætning 3.2 siger, at hvis $A \in R^{nxn}$ er en Markov matrice, så er den spektral radius (det største egenværdi i modulus) lig med 1. For at bevise dette, antager vi at der er en egenværdi $\lambda$ med en egenvektor $v$, så $A^kv = \lambda^kv$, hvor k er et positiv heltal. Men da $A^k$ er en Markov matrix, så er summen af hver række = 1, hvilket kan ikke matche med $\lambda^kv$, hvis $|\lambda| > 1$, da $|\lambda^k|$ vokser større som k øges, så det er en modsætning. Så spektral radius kan kun være mindre eller lig med 1.

\subsection*{Problem 4.}

Lad $A \in \mathbb{R}^{n \times n}$ være en Markov-matrix og $0 < \tau < 1$. Vi ser på: 
$$A_\tau = \tau A + \frac{1-\tau}{n} \mathbf{E}_n$$
hvor $\mathbf{E}_n = \begin{bmatrix} 1 & 1 & ... & 1\\ \vdots & \vdots & \ddots & \vdots\\ 1 & 1 & ... & 1 \end{bmatrix}$ er en $n \times n$ matrix af ens tal.\\

For at vise, at $A_\tau$ også er en Markov-matrix, skal vi bevise, at:
\begin{enumerate}
    \item Alle elementer i $A_\tau$ er ikke-negative.
    \item Summen af alle elementer i hver række i $A_\tau$ er lig med 1.
    \item Da $\tau A$ og $\frac{1-\tau}{n} \mathbf{E}n$ begge er ikke-negative matricer og vi tilføjer dem sammen, er alle elementer i $A\tau$ også non-negative.
    \item Summen af elementerne i række "i" i $A_\tau$ er:
    
    $$(A_\tau)_{i1} + (A_\tau)_{i2} + ... + (A_\tau)_{in}$$ 

$$\tau A_{i1} + \tau A_{i2} + ... + \tau A_{in} + \frac{(1 - \tau)}{n}\cdot (1+1+...+1)$$

$$\tau(A_{i1} + A_{i2} + ... + A_{in}) + (1 - \tau) = 1$$

\end{enumerate}


Som det ses i de ovenstående ligninger, er summen af elementerne i række "i" i $A_\tau$ lig med 1, hvilket betyder at $A_\tau$ er en Markov-matrix.

\subsection*{Problem 5.}

Hvis $A$ er en Markov-matrix med stærkt positive elementer ($a_{ij} > 0$ for alle $i$,$j$), kan man bevise at der kun er én egenværdi $\lambda$ med $|\lambda| = 1$, nemlig $\lambda = 1$, og at den tilsvarende egenvektor er $E_1 = span {\mathbf{e}}$. Enhver anden egenværdi har en modulus mindre end 1.

Man kan bevise dette ved at antage at $\lambda$ er en egenværdi med $|\lambda| = 1$ og $\mathbf{v}$ er en tilsvarende egenvektor. Lad $k$ være en indeksering således at $||\mathbf{v}||_\infty = |v_k|$. Så kan man skrive:
$$||\mathbf{v}||_\infty = |\lambda ||v_k| = |\lambda v_k| = |A\mathbf{v_k}|$$
Ved hjælp af trekantens lighed kan man bevise at:
$$||\mathbf{v}||\infty = |A\mathbf{v_k}| \leq \sum{j=1}^n |a_{jk} v_j| \leq \sum_{j=1}^n a_{jk} |v_j|$$
Da matricen $A$ er en Markov-matrix og egenvektoren $\mathbf{v}$ har positive elementer, kan man skrive:
$$||\mathbf{v}||\infty \leq \sum{j=1}^n a_{jk} |v_j| = ||\mathbf{v}||_\infty$$
Dette er kun sandt hvis alle de ligheder er lige. Det betyder at alle elementerne i egenvektoren er ens og egenvektoren er en multiplum af vektoren med alle 1'ere. Derfor er den eneste egenværdi med $|\lambda| = 1$ $\lambda = 1$ og den tilsvarende egenvektor er $E_1 = span \{\mathbf{e}\}$.

For at vise at andre egenværdier har en modulus mindre end 1, lader vi $\lambda$ være en egenværdi af $A$ således at $|\lambda| > 1$ og $\mathbf{v}$ være en tilsvarende egenvektor. Så har man:
$$|\lambda^n||\mathbf{v}||\infty > ||\mathbf{v}||_\infty$$
Dette strider mod at $A$ er en Markov-matrix, hvor alle elementerne i $A^n$ er positive og summen er 1. Derfor skal alle andre egenværdier have en modulus mindre end 1.


\subsection*{Problem 6.}
PageRank algoritmen, som bruges til at rangere vigtigheden af web sider, bygger på idéen om en "tilfældig surfer" der bevæger sig gennem internettet og følger links. Sandsynligheden for at bevæge sig fra en web side til en anden repræsenteres af en Markov matrice, og den stationære fordeling af denne matrice repræsenterer den langsigtede sandsynlighed for at være på hver side. PageRank algoritmen bruger den stationære fordeling af Markov matricen til at rangere vigtigheden af web siderne, med sider der har en højere sandsynlighed i den stationære fordeling som er betragtes som mere vigtige.

I korthed, sætning 3.4 er relevant for PageRank algoritmen fordi den giver en matematisk begrundelse for at bruge den stationære fordeling af en Markov matrice til at rangere vigtigheden af web sider i algoritmen. Derudover giver sætningen en måde at beregne den stationære fordeling af matricen, som er afgørende for algoritmen.

\subsection*{Problem 7.}

Sætning 3.4 siger, at hvis $A$ er en $n \times n$ matrice med $n$ forskellige egenværdier, så findes der en matrice $V$, hvis kolonner er egenvektorer af $A$ og en diagonalmatrice $D$, hvis diagonalelementer er egenværdierne af $A$, således at $A = VDV^{-1}$.

For at bevise dette i tilfælde, hvor $A$ har $n$ forskellige egenværdier, kan vi bruge faktummet, at $B = V DV^{t}$ er diagonaliserbar. Vi ved, at $B^k = V D^{k} V^{t}$, hvor $D^{k}$ er matricen, der opnås ved at løfte hver del i $D$ til $k$'ende potens. Da $D$ er en diagonalmatrice, er dets egenvektorer de standard basisvektorer, og at løfte hver del til $k$'ende potens multiplicerer den tilsvarende egenværdi med $k$.

Således $B^k = V D^{k} V^{t} = V diag(\lambda_1^k, \lambda_2^k, . . . \lambda_n^k) V^{t}$. Da egenværdierne af $A$ er forskellige, er matricen $V$ inverterbar, så vi kan skrive $A = VDV^{-1}$.

Dermed er Sætning 3.4 bevist for tilfældet, hvor $A$ har $n$ forskellige egenværdier.

Sætning 3.4 siger at der findes en $n \times n$ matrix $A$, der har n forskellige egenvektore. I det tilfælde findes der en basisvektor $V = [v_1,v_2,...v_n]$, og en diagonalmatrice $D$ med egenværdierne i diagonalen. I dette tilfælde kan det skrives som følgemde: $A=VDV^1$.

For at vise at $A$ har n forskellige egemværdier, kan vi bruge den viden om at $B = VDV^{-1}$ faktisk er diagonaliserbar.Vi ved, at $B^k = V D^k (V^{-1})^t = V D^k V^t$, hvor $D^k$ er matricen der opnås ved at løfte hver del i $D$ til $k$'ende potens. Ved at bruge dette kan man vise, at grænsen af $A^k$, hvor k løber mod uendeligt. Det kommer til at se ud som følgende:

$$\lim_{k \rightarrow \infty} A^k = \lim_{k \rightarrow \infty} V D^k V^{-1} $$

Her bliver $D$ til diagonalmatricen, da $k$ løber mod uendeligt. 
$$V \lim_{k \rightarrow \infty} D^k V^{-1} = V \text{diag}(1, 1, \dots, 1) V^{-1} $$

Og til sidst ses det hvordan vi får identitetsmatricen $I$
$$ VV^{-1} = I$$

Nu kan vi så lade $L = \lim_{k \rightarrow \infty} A^k$, da alle kolonner i L skal være egenvektorer af At med egenværdi 1, og da kolonnerne i L er multipler af hinanden, kan man konkludere, at L er en Markovmatrix.

%Markov matricen er en matrice hvis alle elementer er positive og hvis kolonnerne summe til 1.

%Til sidst, da L er en Markovmatrix, kolonnerne i L er multipler af hinanden, og er egenvektorer af At med egenværdi 1, kan man konkludere, at A har n forskellige egenværdier.

%Derfor er sætning 3.4 bevist for tilfældet, hvor A har n forskellige egenværdier






